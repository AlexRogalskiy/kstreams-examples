= Kafka Streams API: A Step Beyond Hello World
Ivan Ponomarev, Synthesized/MIPT
:revealjs_theme: black
:revealjs_customtheme: white_course.css
:revealjs_slideNumber:
:revealjs_history:
:revealjs_progress:
:encoding: UTF-8
:lang: ru
include::_doc_general_attributes.adoc[]
:doctype: article
:toclevels: 3
:imagesdir: images
:source-highlighter: highlightjs
:highlightjsdir: highlight
:icons: font
:iconfont-remote!:
:iconfont-name: font-awesome-4.7.0/css/font-awesome
:revealjs_mouseWheel: true
:revealjs_center: false
:revealjs_transition: none
:revealjs_width: 1600
:revealjs_height: 900
:stem: latexmath

//== Part 1. Intro
:!figure-caption:

ponomarev@corchestra.ru

icon:twitter[size=lg] @inponomarev

== Our plan

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|

Lecture 1.

. [line-through]#Kafka (brief reminder) and Data Streaming#
. [line-through]#Application configuration. Stateless transformations#
. [line-through]#Transformations with local state #

Lecture 2.

. Stream-table dualism and Table joins
. Time and window operations

.^|image::kafka.jpg[]
|===


== Tables vs Streams

User Location

. Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-latestLocation.gif[{image-100-width}]

== Tables vs Streams

Number of places visited

. Michael G. Noll. Of Streams and Tables in Kafka and Stream Processing
image::stream-table-animation-numVisitedLocations.gif[{image-100-width}]

== Tables vs Streams

Derivative and integral

[stem] 
++++
\huge
state(now) = \int\limits_{t=0}^{now} stream(t)\, \mathrm{d}t
\quad\quad
stream(t) = \frac{\mathrm{d}state(t)}{\mathrm{d}t}
++++

Martin Kleppmann, “Designing Data Intensive Applications”

== Table-table join

[stem] 
++++
\huge
(uv)'= u'v + uv'
++++

[.fragment]
image::table-table.svg[{image-40-width}]

== Table-Table join

[stem] 
++++
\huge
(uv)'= u'v + uv'
++++


image::table-table1.svg[{image-40-width}]

== Table-Table join

[stem] 
++++
\huge
(uv)'= u'v + uv'
++++


image::table-table2.svg[{image-40-width}]

== Table-Table join topology

[graphviz, "join-storages.png"]
-----
digraph G {
graph [ dpi = 150 ]; 
rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
Store1 [shape="cylinder"; label="Local Store 1"; fixedsize="true"; width="1.7"]
Store2 [shape="cylinder"; label="Local Store 2"; fixedsize="true"; width="1.7"]
Source1 -> Join
Source2 -> Join

Join -> Sink
Join -> Store1 [dir=both; label=" \n "]
Join -> Store2 [dir=both; label=" \n "]
Store1 -> Store2 [style=invis]
{rank = same; Store1; Join }
}
-----

== Rewriting the totalling app using KTable

[source,java]
----
KTable<String, Long> totals = input.groupByKey().aggregate(
    () -> 0L, 
    (k, v, a) -> a + Math.round(v.getAmount() * v.getOdds()),
    Materialized.with(Serdes.String(), Serdes.Long())
);
----

[source,code]
----
$kafka-topics --zookeeper localhost --describe

Topic: 
table2-demo-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog 
PartitionCount:10
ReplicationFactor:1
Configs:cleanup.policy=compact
----


== Get a table of match scores
[source,java]
----
KStream<String, Score> scores = 
    eventScores.flatMap((k, v) ->
        Stream.of(Outcome.H, Outcome.A).map(o ->
            KeyValue.pair(String.format("%s:%s", k, o), v))
            .collect(Collectors.toList()))
    .mapValues(EventScore::getScore);

KTable<String, Score> tableScores =
    scores.groupByKey(Grouped.with(...). reduce((a, b) -> b);

[source,code]
----
$kafka-topics --zookeeper localhost --describe

table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-repartition
table2-demo-KSTREAM-REDUCE-STATE-STORE-0000000006-changelog
----

== Demo: Combining the amount of bets with the current account
[source,java]
----
KTable<String, String> joined = 
    totals.join(tableScores,
            (total, eventScore) -> 
                String.format("(%s)\t%d", eventScore, total));
----


== Co-partitioning

Join works

[graphviz, "copart-norm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        
          
          subgraph cluster_pp11{
              label = "Partition 2"
          
              b [label = "B"];
              c[label = "C"];
              
          }
          subgraph cluster_pp12{
              label = "Partition 2"
              labelloc ="b"
          
              b1 [label = "B"];
              
              c1[label = "C"];
          }
          
          subgraph cluster_p1{
              label = "Partition 1"
          labelloc = "b"
              
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
              
              
              a [label = "A"];
              
          }
          
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
    subgraph cluster_p2 {
      label = "Worker 2";
         subgraph cluster_pp2{
              label = "Partition 3"
                
              d[label = "D"];
              
              
          }
          subgraph cluster_p2{
              label = "Partition 3"
              labelloc = "b"
              d1[label = "D"];
              
              
          }
          
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Number of partitions mismatch

Join does not work (Runtime Exception)

[graphviz, "copart-diff.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
              b1 [label = "B"]
              a1 [label = "A"]
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
              
              a [label = "A"];
              
          }
          
          subgraph cluster_pa2{
              label = "Partition 2"
          b [label = "B"];
              c [label = "C" color="red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          
          
    subgraph cluster_p2 {
      label = "Worker 2";
         subgraph cluster_pp2{
              label = "Partition 3"
          
              d[label = "D"];
              
              
          }
          subgraph cluster_pa3{
              label = "Partition 2"
              labelloc = "b"
          
              d1[label = "D"];
              c1[label = "C" color ="red"];
              
          }
          c->c1[ dir="none" color="red"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Participle algorithm mismatch

Join doesn't work silently!

[graphviz, "copart-diff-algorithm.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "Source 2"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = "Partition 1"
              labelloc = "b"
          
              b1 [label = "B" color="red"]
              a1 [label = "A"]
              
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
               c[label = "C" color= "red"];
              a [label = "A"];
              
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
          b [label = "B" color="red"];
              d[label = "D"];
             
              
          }
          subgraph cluster_p2{
              label = "Partition 2"
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" color = "red"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[color="red" dir="none"];
          c->c1[color="red" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== GlobalKTable

Replicates everywhere entirely

[source,java]
----
GlobalKTable<...> global = streamsBuilder.globalTable("global", ...);
----

[graphviz, "globalktable.png"]
-----
digraph D {
  graph [ dpi = 150 ]; 
  subgraph system {
     subgraph cluster_s2{
          style = "invis"
          S1 [shape=plaintext label = "Source 1"];
          S2 [shape=plaintext label = "GlobalKTable"];
          S1->S2 [style="invis"]
      }
    subgraph cluster_p1 {
      label = "Worker 1";
        subgraph cluster_p1{
              label = ""
          
              b1 [label = "B"]
              a1 [label = "A"]
              cc [label = "C"] 
              dd [label = "D"]
              a1->cc[style="invis"];
              b1->dd[style="invis"];
          }
          
        subgraph cluster_pp1{
              label = "Partition 1"
          
             
              a [label = "A"];
              b [label = "B"];
          }
          
    }
    subgraph cluster_p2 {
      label = "Worker 2";
      subgraph cluster_pp2{
              label = "Partition 2"
                c[label = "C"];
              
              d[label = "D"];
              
             
              
          }
          subgraph cluster_p2{
              label = ""
              labelloc = "b"
              d1[label = "D"];
              c1[label = "C" ];
              aa[label = "A"];
              bbb[label = "B"];
              c1->aa [style= "invis"];
              d1->bbb [style= "invis"];
              
          }
          a->a1[style="dashed" dir="none"];
          b->b1[style="dashed" dir="none"];
          c->c1[style="dashed" dir="none"];
          d->d1[style="dashed" dir="none"];
    }
  }
} 
-----

== Foreign Key Joins: join + `ForeignKeyExtractor`

[graphviz, "fkjoin.png"]
-----
digraph G {
graph [ dpi = 140 ]; 
#rankdir="LR";
node [fontsize=18; shape="circle"; fixedsize="true"; width="1.1"];
{rank=min; Source1; Source2};
{rank=same; Join1; Join2; Store1;Store2};

Store1 [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.7"]
Store2 [shape="cylinder"; label="Local Store"; fixedsize="true"; width="1.7"]
Source1 -> Join1
Source2 -> Join2
Join1 -> subscribe -> Join2;
Join1 -> update -> Join2[dir=back];
subscribe[shape=record;label=" | | | | ";xlabel="subscribe"];
update[shape=record;label=" | | | | ";xlabel="update"];
Join1 -> Sink
Join2 -> Store1 [dir=both; label=" \n "]
Join2 -> Store2 [dir=both; label=" \n "]

subscribe->update[style=invis];

}
-----


== Operations on Streams and Tables: summary
.Source: https://kafka.apache.org/20/documentation/streams/developer-guide/dsl-api.html#stateful-transformations[Kafka Streams DSL Documentation]
image::streams-stateful_operations.png[{image-50-width}]

== Types of joins: Table-Table

image::table-table.svg[{image-40-width}]

== Types of joins: Table-Table

image::table-table1.svg[{image-40-width}]

== Types of joins: Table-Table

image::table-table2.svg[{image-40-width}]

== Types of joins: Stream-Table

image::stream-table.svg[{image-40-width}]

== Types of joins: Stream-Stream

image::stream-stream.svg[{image-40-width}]


== Our plan
[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|

Lecture 1.

. [line-through]#Kafka (brief reminder) and Data Streaming#
. [line-through]#Application configuration. Stateless transformations#
. [line-through]#Transformations with local state #

Lecture 2.

. [line-through]#Stream-table dualism and table joins#
. *Time and window operations*

.^|image::kafka.jpg[]
|===



== Save Timestamped values to {nbsp}RocksDB

WindowKeySchema.java

[source,java]
----
static Bytes toStoreKeyBinary(byte[] serializedKey,
                              long timestamp,
                              int seqnum) {
    ByteBuffer buf = ByteBuffer.allocate(
                                serializedKey.length
                                + TIMESTAMP_SIZE 
                                + SEQNUM_SIZE);
    buf.put(serializedKey);
    buf.putLong(timestamp);
    buf.putInt(seqnum);
    return Bytes.wrap(buf.array());
}
----

== Quick retrieval of key values for a time range

[graphviz, "timestamped-record.png"]
-----
digraph G
{
    graph [ dpi = 150 ]; 
    node [shape=record, fontsize=18];
    node0 [label="..."];
    node1 [label="<f0> key|<f1> timestamp|<f2> seqnum"];
    node2 [label="..."];
    node0 -> node1;
    node0 -> node2;
}
-----</f2></f1></f0>

== Demo: Windowed Joins

* "Post-scorer" - a player trying to push the correct bet at the time of changing the score in the match
* The time stamp of the bet and the events of the change of account must "almost coincide".

image::livebet.jpg[{image-50-width}]

== Time, Forward!

[source,java]
----
KStream<String, Bet> bets = streamsBuilder.stream(BET_TOPIC,
    Consumed.with(
            Serdes...)
            .withTimestampExtractor(
                
                (record, previousTimestamp) ->
                    ((Bet) record.value()).getTimestamp()

            ));
----
(Time can also be extracted from WallClock and RecordMetadata.)


== Demo: Windowed Joins
По событию смены счёта понимаем, какая ставка будет «правильной»:
[source,java]
----

Score current = Optional.ofNullable(stateStore.get(key))
                .orElse(new Score());
stateStore.put(key, value.getScore());

Outcome currenOutcome = 
    value.getScore().getHome() > current.getHome() 
    ?
    Outcome.H : Outcome.A;
----

== Demo: Windowed Joins
[source, java]
----
KStream<String, String> join = bets.join(outcomes,
    (bet, sureBet) -> 
    
    String.format("%s %dms before goal", 
                bet.getBettor(),
                sureBet.getTimestamp() - bet.getTimestamp()),
                JoinWindows.of(Duration.ofSeconds(1)).before(Duration.ZERO),
                StreamJoined.with(Serdes....
    ));
----


== Tumbling window

[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
----
Source: Kafka Streams in Action
image::tumbling-window.png[{image-70-width}]

== Tumbling window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20)));
    
KTable<Windowed<...>, Long> count = windowed.count();

/*
* Windowed<K> interface:
* - K key()
* - Window window()
* -- Instant startTime()
* -- Instant endTime()
*/
----</K>

== Hopping Window
[source,java]
----
TimeWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(TimeWindows.of(Duration.ofSeconds(20))
                        .advanceBy(Duration.ofSeconds(10)));
----
Source: Kafka Streams in Action
image::hopping-window.png[{image-50-width}]

== Session Window
[source,java]
----
SessionWindowedKStream<..., ...> windowed = 
    stream.groupByKey()
        .windowedBy(SessionWindows.with(Duration.ofMinutes(5)));
----
image::streams-session-windows-02.png[{image-50-width}]

== Window Retention time vs. Grace Time

image::window-retention.png[]


== Sometimes you don't need windows, but Punctuator

[.custom-style]
[cols="30a,70a"]
|===
|image::metronome.jpg[]
|
[source,java]
----
class MyTransformer implements Transformer<...> {
    @Override
    public void init(ProcessorContext context) {
    
        context.schedule(
            Duration.ofSeconds(10),
            PunctuationType.WALL_CLOCK_TIME,
            timestamp->{. . .});
            
    }
----
|===

== Our plan

[cols="20a,60a,20a"]
|===
.^|image::kafka.jpg[]
.^|

Lecture 1.

. [line-through]#Kafka (brief reminder) and Data Streaming#
. [line-through]#Application configuration. Stateless transformations#
. [line-through]#Transformations with local state #

Lecture 2.

. [line-through]#Stream-table dualism and table joins#
. [line-through]#Time and window operations#

.^|image::kafka.jpg[]
|===

*It's time to wrap up!*

== Kafka Streams in Action

[.custom-style]
[cols="30a,70a"]
|===
|image::KSIA.png[]
|
* **William Bejeck**, + 
“Kafka Streams in Action, Second Edition”, Spring 2023?
* The first edition is out of date!
|===

== Kafka: The Definitive Guide

[.custom-style]
[cols="30a,70a"]
|===
|image::kafka-the-definitive-guide.jpg[]
|
* Gwen Shapira, Todd Palino, Rajini Sivaram, Krit Petty
* November 2021
|===



== Other sources

- https://docs.confluent.io/current/streams/developer-guide/index.html[docs.confluent.io: Streams Developer Guide]
- https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications[Getting Your Feet Wet with Stream Processing (Confluent tutorials)]
- Source code!
** https://github.com/apache/kafka/
** https://github.com/spring-projects/spring-kafka

== Communities, conferences
- Telegram: Grefnevaya Kafka
** https://t.me/AwesomeKafka_ru
** https://t.me/proKafka
- Kafka Summit Conference

== Conclusions

[%step]
* Kafka StreamsAPI is a convenient abstraction over the "raw" Kafka
* To start using, you need to understand stream processing
* Technology is being rapidly developed
** + live community, there is a chance to influence the process yourself 
** - public interfaces change very quickly

== That's all!

icon:github[size=lg] https://github.com/inponomarev/kstreams-examples[inponomarev/kstreams-examples]

* icon:twitter[size=lg] https://twitter.com/inponomarev[@inponomarev]

ponomarev@corchestra.ru

*Thanks!*